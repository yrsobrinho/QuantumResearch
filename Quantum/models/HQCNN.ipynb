{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.017426Z",
     "start_time": "2024-08-29T20:17:54.207404Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import qiskit\n",
    "from qiskit import transpile\n",
    "import torch\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit import transpile, QuantumCircuit as QiskitQuantumCircuit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torchxrayvision as xrv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from torchvision.io import read_image\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, random, json, cv2, math\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.020898Z",
     "start_time": "2024-08-29T20:17:57.018429Z"
    }
   },
   "outputs": [],
   "source": [
    "QC_outputs = ['000', '001', '010', '011', '100', '101', '110', '111']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.025396Z",
     "start_time": "2024-08-29T20:17:57.020898Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class MammoDataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True, data_augmentation=False):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Define the base transform\n",
    "        base_transform = [transforms.Resize((250, 250)),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize(mean=[0.3577, 0.3577, 0.3577], std=[0.2662, 0.2662, 0.2662])]\n",
    "        \n",
    "        # Add data augmentation if specified\n",
    "        if train and data_augmentation:\n",
    "            augmentation_transform = [transforms.RandomVerticalFlip(),\n",
    "                                      transforms.GaussianBlur(kernel_size=(3, 3))]\n",
    "            self.transform = transforms.Compose(augmentation_transform + base_transform)\n",
    "        else:\n",
    "            self.transform = transforms.Compose(base_transform)\n",
    "        \n",
    "        # Collect image paths and labels\n",
    "        for label in ['0', '1']:\n",
    "            folder_path = os.path.join(root_dir, label)\n",
    "            self.image_paths.extend([os.path.join(folder_path, img_name) for img_name in os.listdir(folder_path)])\n",
    "            self.labels.extend([int(label)] * len(os.listdir(folder_path)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(torch.nn.Module):\n",
    "    def __init__(self, out_features = 2):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, out_features)\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.036477Z",
     "start_time": "2024-08-29T20:17:57.030381Z"
    }
   },
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    \"\"\" \n",
    "    This class provides a simple interface for interaction \n",
    "    with the quantum circuit \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta_0 = qiskit.circuit.Parameter('theta0')\n",
    "        \n",
    "        self._circuit.h(all_qubits)\n",
    "        self._circuit.barrier()\n",
    "        self._circuit.ry(self.theta_0, all_qubits)\n",
    "        #self._circuit.rx(self.theta, all_qubits)\n",
    "        \n",
    "        self._circuit.measure_all()\n",
    "        # ---------------------------\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "    \n",
    "    def run(self, thetas):\n",
    "        param_values = {\n",
    "            self.theta_0: thetas[0],\n",
    "        }\n",
    "        \n",
    "\n",
    "        bound_circuit = self._circuit.assign_parameters(param_values)\n",
    "\n",
    "        transpiled_circuit = transpile(bound_circuit, self.backend)\n",
    "\n",
    "        job = self.backend.run(transpiled_circuit, shots=self.shots)\n",
    "        \n",
    "        result = job.result().get_counts()\n",
    "        \n",
    "        expectations = []\n",
    "        if type(result)==list:\n",
    "            for i in result:\n",
    "                counts = np.array(list(i.values()))\n",
    "                states = np.array(list(i.keys())).astype(float)\n",
    "            \n",
    "                # Compute probabilities for each state\n",
    "                probabilities = counts / self.shots\n",
    "                # Get state expectation\n",
    "                expectation = np.sum(states * probabilities)\n",
    "\n",
    "                expectations.append(expectation)\n",
    "        else:\n",
    "            counts = np.array(list(result.values()))\n",
    "            states = np.array(list(result.keys())).astype(float)\n",
    "        \n",
    "            # Compute probabilities for each state\n",
    "            probabilities = counts / self.shots\n",
    "            # Get state expectation\n",
    "            expectation = np.sum(states * probabilities)\n",
    "\n",
    "            expectations.append(expectation)\n",
    "        return np.array(expectations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.041872Z",
     "start_time": "2024-08-29T20:17:57.037481Z"
    }
   },
   "outputs": [],
   "source": [
    "class HybridFunction(torch.autograd.Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "        expectation_z = ctx.quantum_circuit.run(input.tolist()[0])\n",
    "        result = torch.tensor([expectation_z])\n",
    "        \n",
    "        ctx.save_for_backward(input, result)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        input_list = np.array(input.tolist()[0])\n",
    "        \n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "        gradients = []\n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run([shift_right[i]])\n",
    "            expectation_left  = ctx.quantum_circuit.run([shift_left[i]])\n",
    "            gradient = expectation_right - expectation_left\n",
    "            gradients.append(gradient)\n",
    "        \n",
    "        gradients = np.array([gradients]).T\n",
    "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
    "\n",
    "\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(n_qubits, backend, shots)\n",
    "        self.shift = shift\n",
    "        \n",
    "    def forward(self, input):\n",
    "        batch_results = []\n",
    "        for i in range(input.shape[0]):\n",
    "            result = HybridFunction.apply(input[i].unsqueeze(0), self.quantum_circuit, self.shift)\n",
    "            batch_results.append(result)\n",
    "        return torch.cat(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.048735Z",
     "start_time": "2024-08-29T20:17:57.041872Z"
    }
   },
   "outputs": [],
   "source": [
    "class qcNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(qcNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 15, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.drop1 = nn.Dropout2d(p=0.2)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.fc1 = nn.Linear(55815, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        sim = AerSimulator(device=\"cuda\")\n",
    "        self.hybrid = Hybrid(self.fc3.out_features, sim, 1000, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.hybrid(x)\n",
    "        x = torch.cat((x, 1 - x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         # Load pre-trained ResNet50 model\n",
    "#         self.resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "#         # Modify the fully connected layer to match the required output features\n",
    "#         self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 84)\n",
    "        \n",
    "#         self.drop1 = nn.Dropout2d(p=0.2)\n",
    "#         self.drop2 = nn.Dropout2d(p=0.5)\n",
    "#         self.fc1 = nn.Linear(84, 1)\n",
    "#         sim = AerSimulator()\n",
    "#         self.hybrid = Hybrid(self.fc1.out_features, sim, 1000, np.pi / 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.resnet(x)\n",
    "#         x = self.drop1(x)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.hybrid(x)\n",
    "#         x = torch.cat((x, 1 - x), -1)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.054984Z",
     "start_time": "2024-08-29T20:17:57.050739Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = 'C:\\\\Users\\\\Win10\\\\PycharmProjects\\\\QuantumResearch\\\\INbreast\\\\data\\\\png\\\\train'\n",
    "test_dir = 'C:\\\\Users\\\\Win10\\\\PycharmProjects\\\\QuantumResearch\\\\INBreast\\\\data\\\\png\\\\test'\n",
    "\n",
    "# Instancia os datasets\n",
    "\n",
    "train_dataset = MammoDataset(root_dir=train_dir, data_augmentation=True)\n",
    "test_dataset = MammoDataset(root_dir=test_dir, train=False)\n",
    "\n",
    "# Cria os DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.844112Z",
     "start_time": "2024-08-29T20:17:57.054984Z"
    }
   },
   "outputs": [],
   "source": [
    "model = qcNet().cpu()\n",
    "loss_func = nn.NLLLoss().cpu()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 10\n",
    "loss_list = []\n",
    "thetas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.845117Z",
     "start_time": "2024-08-29T20:17:57.845117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4610, 0.5390],\n",
      "        [0.4520, 0.5480],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.4870, 0.5130],\n",
      "        [0.4450, 0.5550],\n",
      "        [0.4730, 0.5270],\n",
      "        [0.4850, 0.5150],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.4470, 0.5530],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.4620, 0.5380],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.4630, 0.5370],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.4420, 0.5580],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4770, 0.5230],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.4910, 0.5090],\n",
      "        [0.4110, 0.5890],\n",
      "        [0.5060, 0.4940],\n",
      "        [0.4920, 0.5080],\n",
      "        [0.4490, 0.5510],\n",
      "        [0.4810, 0.5190],\n",
      "        [0.4710, 0.5290],\n",
      "        [0.4750, 0.5250],\n",
      "        [0.4690, 0.5310]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4812\n",
      "tensor([[0.8020, 0.1980],\n",
      "        [0.7650, 0.2350],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.9420, 0.0580],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.5030, 0.4970],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.3050, 0.6950],\n",
      "        [0.8100, 0.1900],\n",
      "        [0.4810, 0.5190],\n",
      "        [0.9390, 0.0610],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.5400, 0.4600],\n",
      "        [0.1000, 0.9000],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.4220, 0.5780],\n",
      "        [0.8430, 0.1570],\n",
      "        [0.3450, 0.6550],\n",
      "        [0.9310, 0.0690],\n",
      "        [0.6860, 0.3140],\n",
      "        [0.1500, 0.8500],\n",
      "        [0.3450, 0.6550],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.7540, 0.2460],\n",
      "        [0.6930, 0.3070]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.4760\n",
      "tensor([[0.0100, 0.9900],\n",
      "        [0.5140, 0.4860],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.9910, 0.0090],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4150, 0.5850],\n",
      "        [0.9630, 0.0370],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.3670, 0.6330],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.3420, 0.6580],\n",
      "        [0.2150, 0.7850],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.1770, 0.8230],\n",
      "        [0.3510, 0.6490],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.7000, 0.3000],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.1500, 0.8500],\n",
      "        [0.0660, 0.9340],\n",
      "        [0.0230, 0.9770],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.7070, 0.2930],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.8170, 0.1830],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.3640, 0.6360]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.6158\n",
      "tensor([[0.0500, 0.9500],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.3420, 0.6580],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.8590, 0.1410],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.4670, 0.5330],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.0870, 0.9130],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.3810, 0.6190],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.2990, 0.7010],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.0800, 0.9200],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.4820, 0.5180],\n",
      "        [0.4420, 0.5580],\n",
      "        [0.8320, 0.1680],\n",
      "        [0.8420, 0.1580],\n",
      "        [0.7590, 0.2410],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.6920, 0.3080],\n",
      "        [0.0750, 0.9250],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.4670, 0.5330],\n",
      "        [0.1050, 0.8950]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.5580\n",
      "tensor([[0.4290, 0.5710],\n",
      "        [0.1660, 0.8340],\n",
      "        [0.2920, 0.7080],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8560, 0.1440],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3070, 0.6930],\n",
      "        [0.0610, 0.9390],\n",
      "        [0.2470, 0.7530],\n",
      "        [0.2690, 0.7310],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.8610, 0.1390],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.8100, 0.1900],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.4730, 0.5270],\n",
      "        [0.0770, 0.9230],\n",
      "        [0.8940, 0.1060],\n",
      "        [0.2690, 0.7310],\n",
      "        [0.8590, 0.1410],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.7630, 0.2370],\n",
      "        [0.6650, 0.3350],\n",
      "        [0.1110, 0.8890]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.5522\n",
      "tensor([[0.6430, 0.3570],\n",
      "        [0.2840, 0.7160],\n",
      "        [0.2780, 0.7220],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.4450, 0.5550],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.7730, 0.2270],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.5730, 0.4270],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.6320, 0.3680],\n",
      "        [0.3320, 0.6680],\n",
      "        [0.2190, 0.7810],\n",
      "        [0.9760, 0.0240],\n",
      "        [0.0750, 0.9250],\n",
      "        [0.7520, 0.2480],\n",
      "        [0.3010, 0.6990],\n",
      "        [0.4360, 0.5640],\n",
      "        [0.8480, 0.1520],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1350, 0.8650],\n",
      "        [0.8840, 0.1160],\n",
      "        [0.9460, 0.0540],\n",
      "        [0.1210, 0.8790],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.7740, 0.2260],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.8030, 0.1970],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.8470, 0.1530]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.5380\n",
      "tensor([[0.0270, 0.9730],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.4330, 0.5670],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.0500, 0.9500],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.1060, 0.8940],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.4420, 0.5580],\n",
      "        [0.2580, 0.7420],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.0760, 0.9240],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.5990, 0.4010],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9390, 0.0610],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.8450, 0.1550],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.8100, 0.1900],\n",
      "        [0.8990, 0.1010],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.9380, 0.0620],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.3290, 0.6710],\n",
      "        [0.3350, 0.6650],\n",
      "        [0.4290, 0.5710],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.9780, 0.0220]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.4872\n",
      "tensor([[0.2500, 0.7500],\n",
      "        [0.4150, 0.5850],\n",
      "        [0.2300, 0.7700],\n",
      "        [0.6220, 0.3780],\n",
      "        [0.4630, 0.5370],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.4620, 0.5380],\n",
      "        [0.7320, 0.2680],\n",
      "        [0.0630, 0.9370],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.9270, 0.0730],\n",
      "        [0.4400, 0.5600],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.7530, 0.2470],\n",
      "        [0.5240, 0.4760],\n",
      "        [0.2150, 0.7850],\n",
      "        [0.2290, 0.7710],\n",
      "        [0.2590, 0.7410],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.6550, 0.3450],\n",
      "        [0.2910, 0.7090],\n",
      "        [0.9680, 0.0320],\n",
      "        [0.3470, 0.6530],\n",
      "        [0.1570, 0.8430],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.5450, 0.4550],\n",
      "        [0.1710, 0.8290],\n",
      "        [0.1070, 0.8930],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.7000, 0.3000]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.5274\n",
      "tensor([[0.0850, 0.9150],\n",
      "        [0.4130, 0.5870],\n",
      "        [0.1690, 0.8310],\n",
      "        [0.1770, 0.8230],\n",
      "        [0.4510, 0.5490],\n",
      "        [0.1770, 0.8230],\n",
      "        [0.0500, 0.9500],\n",
      "        [0.3200, 0.6800],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.6220, 0.3780],\n",
      "        [0.8320, 0.1680],\n",
      "        [0.9460, 0.0540],\n",
      "        [0.4940, 0.5060],\n",
      "        [0.9110, 0.0890],\n",
      "        [0.1500, 0.8500],\n",
      "        [0.8640, 0.1360],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.4630, 0.5370],\n",
      "        [0.8930, 0.1070],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.4630, 0.5370],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.3300, 0.6700],\n",
      "        [0.8440, 0.1560],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9780, 0.0220],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.5910, 0.4090],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.9190, 0.0810]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.4818\n",
      "tensor([[0.0010, 0.9990],\n",
      "        [0.2080, 0.7920],\n",
      "        [0.9540, 0.0460],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2460, 0.7540],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.2230, 0.7770],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.4630, 0.5370],\n",
      "        [0.5450, 0.4550],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.2270, 0.7730],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.6250, 0.3750],\n",
      "        [0.0980, 0.9020],\n",
      "        [0.6350, 0.3650],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.4850, 0.5150],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.2170, 0.7830],\n",
      "        [0.2070, 0.7930],\n",
      "        [0.7370, 0.2630],\n",
      "        [0.5820, 0.4180],\n",
      "        [0.0470, 0.9530]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.5191\n",
      "tensor([[0.6510, 0.3490],\n",
      "        [0.4420, 0.5580],\n",
      "        [0.2730, 0.7270],\n",
      "        [0.8500, 0.1500],\n",
      "        [0.9250, 0.0750],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.1110, 0.8890]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.5264\n",
      "Epoch 1/10, Loss: -0.5239062499999999\n",
      "tensor([[0.2930, 0.7070],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.1450, 0.8550],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.7200, 0.2800],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.0440, 0.9560],\n",
      "        [0.8430, 0.1570],\n",
      "        [0.9630, 0.0370],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.0580, 0.9420],\n",
      "        [0.2710, 0.7290],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.3540, 0.6460],\n",
      "        [0.6730, 0.3270],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.2010, 0.7990],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.9780, 0.0220],\n",
      "        [0.4420, 0.5580],\n",
      "        [0.3360, 0.6640],\n",
      "        [0.6230, 0.3770],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.1110, 0.8890]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.5061\n",
      "tensor([[0.5540, 0.4460],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.0570, 0.9430],\n",
      "        [0.5880, 0.4120],\n",
      "        [0.4370, 0.5630],\n",
      "        [0.8390, 0.1610],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.4980, 0.5020],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.5930, 0.4070],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.3130, 0.6870],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.6040, 0.3960],\n",
      "        [0.6120, 0.3880],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.1740, 0.8260],\n",
      "        [0.1310, 0.8690],\n",
      "        [0.9250, 0.0750],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.6120, 0.3880]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.4457\n",
      "tensor([[0.5760, 0.4240],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.9040, 0.0960],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.5900, 0.4100],\n",
      "        [0.9760, 0.0240],\n",
      "        [0.4970, 0.5030],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.6900, 0.3100],\n",
      "        [0.8960, 0.1040],\n",
      "        [0.9220, 0.0780],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0900, 0.9100],\n",
      "        [0.8220, 0.1780],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.7400, 0.2600],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.4180, 0.5820],\n",
      "        [0.6260, 0.3740],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.6660, 0.3340],\n",
      "        [0.3670, 0.6330],\n",
      "        [0.9260, 0.0740]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5544\n",
      "tensor([[0.5910, 0.4090],\n",
      "        [0.1860, 0.8140],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.4490, 0.5510],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.3190, 0.6810],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.7480, 0.2520],\n",
      "        [0.3010, 0.6990],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.7900, 0.2100],\n",
      "        [0.5030, 0.4970],\n",
      "        [0.5980, 0.4020],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.5520, 0.4480],\n",
      "        [0.8780, 0.1220],\n",
      "        [0.2840, 0.7160],\n",
      "        [0.1570, 0.8430],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.8560, 0.1440],\n",
      "        [0.1540, 0.8460],\n",
      "        [0.0960, 0.9040],\n",
      "        [0.3610, 0.6390],\n",
      "        [0.3580, 0.6420]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.4643\n",
      "tensor([[0.8950, 0.1050],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.9030, 0.0970],\n",
      "        [0.9460, 0.0540],\n",
      "        [0.9110, 0.0890],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.6590, 0.3410],\n",
      "        [0.6130, 0.3870],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.3320, 0.6680],\n",
      "        [0.0690, 0.9310],\n",
      "        [0.6220, 0.3780],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.6760, 0.3240],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.4640, 0.5360],\n",
      "        [0.5060, 0.4940],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1070, 0.8930],\n",
      "        [0.1350, 0.8650],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.1670, 0.8330],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.6780, 0.3220],\n",
      "        [0.2490, 0.7510]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.5095\n",
      "tensor([[0.0290, 0.9710],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.0650, 0.9350],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.7560, 0.2440],\n",
      "        [0.8040, 0.1960],\n",
      "        [0.5990, 0.4010],\n",
      "        [0.8030, 0.1970],\n",
      "        [0.3050, 0.6950],\n",
      "        [0.8710, 0.1290],\n",
      "        [0.0770, 0.9230],\n",
      "        [0.6350, 0.3650],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1020, 0.8980],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.7200, 0.2800],\n",
      "        [0.7280, 0.2720],\n",
      "        [0.7530, 0.2470],\n",
      "        [0.6920, 0.3080],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.1000, 0.9000],\n",
      "        [0.4470, 0.5530],\n",
      "        [0.8150, 0.1850],\n",
      "        [0.0570, 0.9430],\n",
      "        [0.4660, 0.5340]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.4385\n",
      "tensor([[0.4420, 0.5580],\n",
      "        [0.6790, 0.3210],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.2780, 0.7220],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.9690, 0.0310],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.4780, 0.5220],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.2480, 0.7520],\n",
      "        [0.3330, 0.6670],\n",
      "        [0.2290, 0.7710],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.7180, 0.2820],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.5160, 0.4840],\n",
      "        [0.7090, 0.2910],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.7980, 0.2020],\n",
      "        [0.8020, 0.1980],\n",
      "        [0.5970, 0.4030],\n",
      "        [0.2480, 0.7520],\n",
      "        [0.5810, 0.4190],\n",
      "        [0.4550, 0.5450],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.9950, 0.0050]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.5241\n",
      "tensor([[0.2620, 0.7380],\n",
      "        [0.1980, 0.8020],\n",
      "        [0.4520, 0.5480],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.2910, 0.7090],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.1120, 0.8880],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.8750, 0.1250],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.4180, 0.5820],\n",
      "        [0.2070, 0.7930],\n",
      "        [0.6930, 0.3070],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.5260, 0.4740],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.8370, 0.1630],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.7250, 0.2750],\n",
      "        [0.6090, 0.3910],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.4800, 0.5200],\n",
      "        [0.3610, 0.6390],\n",
      "        [0.4400, 0.5600],\n",
      "        [0.3590, 0.6410],\n",
      "        [0.9330, 0.0670],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.1820, 0.8180],\n",
      "        [0.2680, 0.7320],\n",
      "        [0.2770, 0.7230]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.4429\n",
      "tensor([[0.8020, 0.1980],\n",
      "        [0.6440, 0.3560],\n",
      "        [0.3060, 0.6940],\n",
      "        [0.9010, 0.0990],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.1740, 0.8260],\n",
      "        [0.6040, 0.3960],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.0950, 0.9050],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.3430, 0.6570],\n",
      "        [0.1540, 0.8460],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2240, 0.7760],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.3490, 0.6510],\n",
      "        [0.7870, 0.2130],\n",
      "        [0.7060, 0.2940],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.7080, 0.2920],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.7980, 0.2020],\n",
      "        [0.2430, 0.7570],\n",
      "        [0.9300, 0.0700],\n",
      "        [0.1710, 0.8290],\n",
      "        [0.4490, 0.5510],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.7220, 0.2780],\n",
      "        [0.8390, 0.1610]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.5480\n",
      "tensor([[0.8250, 0.1750],\n",
      "        [0.4010, 0.5990],\n",
      "        [0.2490, 0.7510],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.9350, 0.0650],\n",
      "        [0.0690, 0.9310],\n",
      "        [0.6970, 0.3030],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.2160, 0.7840],\n",
      "        [0.8720, 0.1280],\n",
      "        [0.8380, 0.1620],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.9220, 0.0780],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.9370, 0.0630],\n",
      "        [0.2600, 0.7400],\n",
      "        [0.3770, 0.6230],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.2990, 0.7010],\n",
      "        [0.6320, 0.3680],\n",
      "        [0.7120, 0.2880],\n",
      "        [0.9390, 0.0610],\n",
      "        [0.1380, 0.8620],\n",
      "        [0.8820, 0.1180],\n",
      "        [0.0030, 0.9970]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.4391\n",
      "tensor([[0.8290, 0.1710],\n",
      "        [0.3530, 0.6470],\n",
      "        [0.5220, 0.4780],\n",
      "        [0.0990, 0.9010],\n",
      "        [0.4460, 0.5540],\n",
      "        [0.3840, 0.6160],\n",
      "        [0.9270, 0.0730],\n",
      "        [0.1630, 0.8370]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.4789\n",
      "Epoch 2/10, Loss: -0.4865028409090908\n",
      "tensor([[0.0830, 0.9170],\n",
      "        [0.8730, 0.1270],\n",
      "        [0.7310, 0.2690],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.3790, 0.6210],\n",
      "        [0.5380, 0.4620],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.4520, 0.5480],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.8540, 0.1460],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.3140, 0.6860],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.3360, 0.6640],\n",
      "        [0.7870, 0.2130],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.2040, 0.7960],\n",
      "        [0.7490, 0.2510],\n",
      "        [0.1400, 0.8600],\n",
      "        [0.7560, 0.2440],\n",
      "        [0.9130, 0.0870],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.9680, 0.0320],\n",
      "        [0.1900, 0.8100],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.5050, 0.4950],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.8110, 0.1890],\n",
      "        [0.8730, 0.1270]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.6311\n",
      "tensor([[0.9740, 0.0260],\n",
      "        [0.3990, 0.6010],\n",
      "        [0.6500, 0.3500],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.8020, 0.1980],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.5900, 0.4100],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.3160, 0.6840],\n",
      "        [0.0440, 0.9560],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.9070, 0.0930],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.2930, 0.7070],\n",
      "        [0.8680, 0.1320],\n",
      "        [0.6410, 0.3590],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.5480, 0.4520],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.4880, 0.5120],\n",
      "        [0.2320, 0.7680],\n",
      "        [0.6500, 0.3500],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.5010, 0.4990],\n",
      "        [0.4880, 0.5120],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.4980, 0.5020]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5207\n",
      "tensor([[0.2650, 0.7350],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.5810, 0.4190],\n",
      "        [0.6750, 0.3250],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.1660, 0.8340],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.9420, 0.0580],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.1930, 0.8070],\n",
      "        [0.4070, 0.5930],\n",
      "        [0.1340, 0.8660],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.7940, 0.2060],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.9340, 0.0660],\n",
      "        [0.1760, 0.8240],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.5400, 0.4600],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.8590, 0.1410],\n",
      "        [0.3800, 0.6200],\n",
      "        [0.5910, 0.4090],\n",
      "        [0.6700, 0.3300],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.9220, 0.0780]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5570\n",
      "tensor([[0.0590, 0.9410],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.3690, 0.6310],\n",
      "        [0.2620, 0.7380],\n",
      "        [0.8960, 0.1040],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.6970, 0.3030],\n",
      "        [0.7750, 0.2250],\n",
      "        [0.9080, 0.0920],\n",
      "        [0.0300, 0.9700],\n",
      "        [0.0930, 0.9070],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.2880, 0.7120],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.4750, 0.5250],\n",
      "        [0.2950, 0.7050],\n",
      "        [0.9190, 0.0810],\n",
      "        [0.7230, 0.2770],\n",
      "        [0.3220, 0.6780],\n",
      "        [0.4070, 0.5930],\n",
      "        [0.2810, 0.7190],\n",
      "        [0.5870, 0.4130],\n",
      "        [0.3410, 0.6590],\n",
      "        [0.3460, 0.6540],\n",
      "        [0.4140, 0.5860],\n",
      "        [0.3470, 0.6530],\n",
      "        [0.7230, 0.2770],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.5860, 0.4140],\n",
      "        [0.1410, 0.8590],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.0540, 0.9460]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.3992\n",
      "tensor([[0.4500, 0.5500],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.3830, 0.6170],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.3010, 0.6990],\n",
      "        [0.1880, 0.8120],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.6250, 0.3750],\n",
      "        [0.2820, 0.7180],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.4390, 0.5610],\n",
      "        [0.3580, 0.6420],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.3040, 0.6960],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.8810, 0.1190],\n",
      "        [0.3950, 0.6050],\n",
      "        [0.3210, 0.6790],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.8570, 0.1430],\n",
      "        [0.6150, 0.3850],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.8250, 0.1750],\n",
      "        [0.1670, 0.8330],\n",
      "        [0.8400, 0.1600],\n",
      "        [0.2240, 0.7760],\n",
      "        [0.9040, 0.0960],\n",
      "        [0.4510, 0.5490]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.4173\n",
      "tensor([[0.1730, 0.8270],\n",
      "        [0.8890, 0.1110],\n",
      "        [0.7120, 0.2880],\n",
      "        [0.4390, 0.5610],\n",
      "        [0.9680, 0.0320],\n",
      "        [0.8600, 0.1400],\n",
      "        [0.1100, 0.8900],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8280, 0.1720],\n",
      "        [0.8920, 0.1080],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.7010, 0.2990],\n",
      "        [0.2030, 0.7970],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.8410, 0.1590],\n",
      "        [0.5350, 0.4650],\n",
      "        [0.5800, 0.4200],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.3010, 0.6990],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.4260, 0.5740],\n",
      "        [0.3540, 0.6460],\n",
      "        [0.3350, 0.6650],\n",
      "        [0.7710, 0.2290],\n",
      "        [0.9680, 0.0320],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.2020, 0.7980],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.7060, 0.2940],\n",
      "        [0.5200, 0.4800]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.5842\n",
      "tensor([[0.0650, 0.9350],\n",
      "        [0.5850, 0.4150],\n",
      "        [0.2130, 0.7870],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.2570, 0.7430],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.1940, 0.8060],\n",
      "        [0.1910, 0.8090],\n",
      "        [0.2990, 0.7010],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.7750, 0.2250],\n",
      "        [0.4230, 0.5770],\n",
      "        [0.3780, 0.6220],\n",
      "        [0.0650, 0.9350],\n",
      "        [0.6050, 0.3950],\n",
      "        [0.1580, 0.8420],\n",
      "        [0.3230, 0.6770],\n",
      "        [0.4430, 0.5570],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.0570, 0.9430],\n",
      "        [0.8340, 0.1660],\n",
      "        [0.5940, 0.4060],\n",
      "        [0.4630, 0.5370],\n",
      "        [0.1760, 0.8240],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.9980, 0.0020]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.3446\n",
      "tensor([[0.5090, 0.4910],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.4750, 0.5250],\n",
      "        [0.3790, 0.6210],\n",
      "        [0.3490, 0.6510],\n",
      "        [0.2860, 0.7140],\n",
      "        [0.2710, 0.7290],\n",
      "        [0.3270, 0.6730],\n",
      "        [0.0570, 0.9430],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.4800, 0.5200],\n",
      "        [0.6150, 0.3850],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0650, 0.9350],\n",
      "        [0.2030, 0.7970],\n",
      "        [0.3580, 0.6420],\n",
      "        [0.3970, 0.6030],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.4670, 0.5330],\n",
      "        [0.0340, 0.9660],\n",
      "        [0.4380, 0.5620],\n",
      "        [0.6650, 0.3350],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.4300, 0.5700],\n",
      "        [0.4350, 0.5650],\n",
      "        [0.3990, 0.6010],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.3580, 0.6420],\n",
      "        [0.6960, 0.3040],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0010, 0.9990]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.4392\n",
      "tensor([[0.6670, 0.3330],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.3170, 0.6830],\n",
      "        [0.1380, 0.8620],\n",
      "        [0.1940, 0.8060],\n",
      "        [0.7130, 0.2870],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.2370, 0.7630],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.4520, 0.5480],\n",
      "        [0.2480, 0.7520],\n",
      "        [0.3680, 0.6320],\n",
      "        [0.4980, 0.5020],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.6570, 0.3430],\n",
      "        [0.5840, 0.4160],\n",
      "        [0.6450, 0.3550],\n",
      "        [0.2230, 0.7770],\n",
      "        [0.6650, 0.3350],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.3730, 0.6270],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.5380, 0.4620],\n",
      "        [0.3220, 0.6780],\n",
      "        [0.8190, 0.1810],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0920, 0.9080],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.2280, 0.7720],\n",
      "        [0.6550, 0.3450]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.4596\n",
      "tensor([[0.1620, 0.8380],\n",
      "        [0.4350, 0.5650],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.8270, 0.1730],\n",
      "        [0.8280, 0.1720],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.0920, 0.9080],\n",
      "        [0.8420, 0.1580],\n",
      "        [0.4810, 0.5190],\n",
      "        [0.1050, 0.8950],\n",
      "        [0.3270, 0.6730],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.4970, 0.5030],\n",
      "        [0.2860, 0.7140],\n",
      "        [0.4250, 0.5750],\n",
      "        [0.9760, 0.0240],\n",
      "        [0.2270, 0.7730],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.1580, 0.8420],\n",
      "        [0.6450, 0.3550],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.8780, 0.1220],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.0490, 0.9510],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2230, 0.7770],\n",
      "        [0.2910, 0.7090],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.3450, 0.6550],\n",
      "        [0.8780, 0.1220],\n",
      "        [0.4710, 0.5290]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.4827\n",
      "tensor([[0.4530, 0.5470],\n",
      "        [0.0940, 0.9060],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.7580, 0.2420],\n",
      "        [0.6560, 0.3440],\n",
      "        [0.4720, 0.5280],\n",
      "        [0.1760, 0.8240]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.3740\n",
      "Epoch 3/10, Loss: -0.47360511363636365\n",
      "tensor([[0.0310, 0.9690],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.2800, 0.7200],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.2130, 0.7870],\n",
      "        [0.4810, 0.5190],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.0640, 0.9360],\n",
      "        [0.0570, 0.9430],\n",
      "        [0.4160, 0.5840],\n",
      "        [0.4180, 0.5820],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.0470, 0.9530],\n",
      "        [0.4320, 0.5680],\n",
      "        [0.4320, 0.5680],\n",
      "        [0.2680, 0.7320],\n",
      "        [0.5050, 0.4950],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.6940, 0.3060],\n",
      "        [0.2620, 0.7380],\n",
      "        [0.4600, 0.5400],\n",
      "        [0.3310, 0.6690],\n",
      "        [0.5720, 0.4280],\n",
      "        [0.1500, 0.8500],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.3430, 0.6570],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.9270, 0.0730]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.3614\n",
      "tensor([[0.0310, 0.9690],\n",
      "        [0.3240, 0.6760],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.6280, 0.3720],\n",
      "        [0.4300, 0.5700],\n",
      "        [0.2770, 0.7230],\n",
      "        [0.2910, 0.7090],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.4400, 0.5600],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.1050, 0.8950],\n",
      "        [0.2460, 0.7540],\n",
      "        [0.0340, 0.9660],\n",
      "        [0.9710, 0.0290],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2940, 0.7060],\n",
      "        [0.9520, 0.0480],\n",
      "        [0.5120, 0.4880],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.9760, 0.0240],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.2020, 0.7980],\n",
      "        [0.1120, 0.8880],\n",
      "        [0.4350, 0.5650],\n",
      "        [0.4950, 0.5050],\n",
      "        [0.3070, 0.6930],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.1300, 0.8700],\n",
      "        [0.3360, 0.6640],\n",
      "        [0.1990, 0.8010]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.3468\n",
      "tensor([[0.4880, 0.5120],\n",
      "        [0.3860, 0.6140],\n",
      "        [0.1070, 0.8930],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1450, 0.8550],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.4410, 0.5590],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.4570, 0.5430],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0390, 0.9610],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.4130, 0.5870],\n",
      "        [0.3780, 0.6220],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1350, 0.8650],\n",
      "        [0.8170, 0.1830],\n",
      "        [0.0610, 0.9390],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.8910, 0.1090],\n",
      "        [0.4470, 0.5530],\n",
      "        [0.2170, 0.7830],\n",
      "        [0.1720, 0.8280],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.1840, 0.8160],\n",
      "        [0.4180, 0.5820],\n",
      "        [0.8960, 0.1040],\n",
      "        [0.3410, 0.6590],\n",
      "        [0.4870, 0.5130],\n",
      "        [0.5040, 0.4960],\n",
      "        [0.4750, 0.5250]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.4701\n",
      "tensor([[0.0470, 0.9530],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.2040, 0.7960],\n",
      "        [0.4750, 0.5250],\n",
      "        [0.3430, 0.6570],\n",
      "        [0.3010, 0.6990],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.8770, 0.1230],\n",
      "        [0.1650, 0.8350],\n",
      "        [0.2380, 0.7620],\n",
      "        [0.1140, 0.8860],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.6840, 0.3160],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.4230, 0.5770],\n",
      "        [0.3880, 0.6120],\n",
      "        [0.4960, 0.5040],\n",
      "        [0.0980, 0.9020],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.8680, 0.1320],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.3020, 0.6980],\n",
      "        [0.4130, 0.5870],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.3420, 0.6580],\n",
      "        [0.2830, 0.7170],\n",
      "        [0.8880, 0.1120]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.4322\n",
      "tensor([[0.2320, 0.7680],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.3680, 0.6320],\n",
      "        [0.5130, 0.4870],\n",
      "        [0.8870, 0.1130],\n",
      "        [0.3150, 0.6850],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.0470, 0.9530],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.5110, 0.4890],\n",
      "        [0.3140, 0.6860],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.4130, 0.5870],\n",
      "        [0.1170, 0.8830],\n",
      "        [0.1440, 0.8560],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.3020, 0.6980],\n",
      "        [0.2120, 0.7880],\n",
      "        [0.3080, 0.6920],\n",
      "        [0.8940, 0.1060],\n",
      "        [0.1400, 0.8600],\n",
      "        [0.4710, 0.5290],\n",
      "        [0.3610, 0.6390],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.9360, 0.0640],\n",
      "        [0.3690, 0.6310],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.4570, 0.5430]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.4230\n",
      "tensor([[0.3790, 0.6210],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.4600, 0.5400],\n",
      "        [0.4520, 0.5480],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.6060, 0.3940],\n",
      "        [0.1640, 0.8360],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.8960, 0.1040],\n",
      "        [0.4740, 0.5260],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.1500, 0.8500],\n",
      "        [0.3460, 0.6540],\n",
      "        [0.2740, 0.7260],\n",
      "        [0.4950, 0.5050],\n",
      "        [0.1360, 0.8640],\n",
      "        [0.1400, 0.8600],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.9180, 0.0820],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.0720, 0.9280],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.9030, 0.0970],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.4810, 0.5190],\n",
      "        [0.8870, 0.1130]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.4951\n",
      "tensor([[0.6240, 0.3760],\n",
      "        [0.1100, 0.8900],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.4970, 0.5030],\n",
      "        [0.6190, 0.3810],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.1310, 0.8690],\n",
      "        [0.1900, 0.8100],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.4770, 0.5230],\n",
      "        [0.3940, 0.6060],\n",
      "        [0.1390, 0.8610],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.0890, 0.9110],\n",
      "        [0.4240, 0.5760],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.8140, 0.1860],\n",
      "        [0.1470, 0.8530],\n",
      "        [0.3170, 0.6830],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.4840, 0.5160],\n",
      "        [0.9680, 0.0320],\n",
      "        [0.1910, 0.8090],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.1670, 0.8330],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0580, 0.9420]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.4644\n",
      "tensor([[0.0240, 0.9760],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.8900, 0.1100],\n",
      "        [0.4820, 0.5180],\n",
      "        [0.2030, 0.7970],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.1070, 0.8930],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.3930, 0.6070],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1750, 0.8250],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.3310, 0.6690],\n",
      "        [0.1740, 0.8260],\n",
      "        [0.9040, 0.0960],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.2130, 0.7870],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.6880, 0.3120],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.5760, 0.4240]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.3544\n",
      "tensor([[0.4260, 0.5740],\n",
      "        [0.4980, 0.5020],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.4850, 0.5150],\n",
      "        [0.0790, 0.9210],\n",
      "        [0.5190, 0.4810],\n",
      "        [0.1090, 0.8910],\n",
      "        [0.8890, 0.1110],\n",
      "        [0.9300, 0.0700],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1960, 0.8040],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.6010, 0.3990],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.7520, 0.2480],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.2260, 0.7740],\n",
      "        [0.4750, 0.5250],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.7780, 0.2220],\n",
      "        [0.3740, 0.6260],\n",
      "        [0.0090, 0.9910]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.4683\n",
      "tensor([[0.6520, 0.3480],\n",
      "        [0.0920, 0.9080],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.5120, 0.4880],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.7720, 0.2280],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.4070, 0.5930],\n",
      "        [0.2820, 0.7180],\n",
      "        [0.8110, 0.1890],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.1360, 0.8640],\n",
      "        [0.4990, 0.5010],\n",
      "        [0.7680, 0.2320],\n",
      "        [0.7990, 0.2010],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.7170, 0.2830],\n",
      "        [0.2520, 0.7480],\n",
      "        [0.4500, 0.5500],\n",
      "        [0.2150, 0.7850],\n",
      "        [0.7840, 0.2160],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.7800, 0.2200],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.2250, 0.7750],\n",
      "        [0.0140, 0.9860]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.4583\n",
      "tensor([[0.4570, 0.5430],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.8310, 0.1690],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0690, 0.9310],\n",
      "        [0.3850, 0.6150],\n",
      "        [0.2990, 0.7010]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.3544\n",
      "Epoch 4/10, Loss: -0.42075\n",
      "tensor([[0.8130, 0.1870],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.2400, 0.7600],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.5140, 0.4860],\n",
      "        [0.5120, 0.4880],\n",
      "        [0.6060, 0.3940],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.7310, 0.2690],\n",
      "        [0.9120, 0.0880],\n",
      "        [0.6740, 0.3260],\n",
      "        [0.2650, 0.7350],\n",
      "        [0.4530, 0.5470],\n",
      "        [0.3400, 0.6600],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.7200, 0.2800],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.6830, 0.3170],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.2300, 0.7700],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.7900, 0.2100],\n",
      "        [0.5310, 0.4690]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4828\n",
      "tensor([[0.0870, 0.9130],\n",
      "        [0.6540, 0.3460],\n",
      "        [0.8260, 0.1740],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.5260, 0.4740],\n",
      "        [0.7650, 0.2350],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.8410, 0.1590],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.3750, 0.6250],\n",
      "        [0.7220, 0.2780],\n",
      "        [0.2380, 0.7620],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.7760, 0.2240],\n",
      "        [0.6100, 0.3900],\n",
      "        [0.1500, 0.8500],\n",
      "        [0.2550, 0.7450],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.9140, 0.0860],\n",
      "        [0.1380, 0.8620],\n",
      "        [0.6900, 0.3100],\n",
      "        [0.8430, 0.1570],\n",
      "        [0.4060, 0.5940],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.5060, 0.4940],\n",
      "        [0.9990, 0.0010]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5178\n",
      "tensor([[0.1060, 0.8940],\n",
      "        [0.7520, 0.2480],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.9250, 0.0750],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.4240, 0.5760],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.8780, 0.1220],\n",
      "        [0.6620, 0.3380],\n",
      "        [0.9270, 0.0730],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.1230, 0.8770],\n",
      "        [0.1860, 0.8140],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.0760, 0.9240],\n",
      "        [0.9390, 0.0610],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.4770, 0.5230],\n",
      "        [0.2110, 0.7890],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.9060, 0.0940],\n",
      "        [0.8130, 0.1870],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.4430, 0.5570],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.4340, 0.5660],\n",
      "        [0.0380, 0.9620]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5339\n",
      "tensor([[0.7070, 0.2930],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.3380, 0.6620],\n",
      "        [0.4040, 0.5960],\n",
      "        [0.8990, 0.1010],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.6910, 0.3090],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0000, 1.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.7670, 0.2330],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.4120, 0.5880],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.1220, 0.8780],\n",
      "        [0.1900, 0.8100],\n",
      "        [0.8370, 0.1630],\n",
      "        [0.9330, 0.0670],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.9030, 0.0970],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.7020, 0.2980],\n",
      "        [0.1720, 0.8280],\n",
      "        [0.1410, 0.8590],\n",
      "        [0.5260, 0.4740],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.8840, 0.1160],\n",
      "        [0.2710, 0.7290],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.4000, 0.6000]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.5198\n",
      "tensor([[0.7340, 0.2660],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.2190, 0.7810],\n",
      "        [0.6990, 0.3010],\n",
      "        [0.6660, 0.3340],\n",
      "        [0.9070, 0.0930],\n",
      "        [0.6000, 0.4000],\n",
      "        [0.2550, 0.7450],\n",
      "        [0.6040, 0.3960],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.1390, 0.8610],\n",
      "        [0.2670, 0.7330],\n",
      "        [0.2760, 0.7240],\n",
      "        [0.4940, 0.5060],\n",
      "        [0.2870, 0.7130],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.5540, 0.4460],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.3510, 0.6490],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.6120, 0.3880],\n",
      "        [0.2350, 0.7650],\n",
      "        [0.1620, 0.8380],\n",
      "        [0.9420, 0.0580],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.8840, 0.1160],\n",
      "        [0.6810, 0.3190],\n",
      "        [0.6240, 0.3760],\n",
      "        [0.0680, 0.9320]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.5253\n",
      "tensor([[0.0860, 0.9140],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.0980, 0.9020],\n",
      "        [0.5600, 0.4400],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.3970, 0.6030],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.2630, 0.7370],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.6500, 0.3500],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.8940, 0.1060],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.6340, 0.3660],\n",
      "        [0.1690, 0.8310],\n",
      "        [0.4920, 0.5080],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.3910, 0.6090],\n",
      "        [0.1460, 0.8540],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.7310, 0.2690],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.9110, 0.0890],\n",
      "        [0.0110, 0.9890]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.4467\n",
      "tensor([[0.9710, 0.0290],\n",
      "        [0.2190, 0.7810],\n",
      "        [0.9510, 0.0490],\n",
      "        [0.4470, 0.5530],\n",
      "        [0.8100, 0.1900],\n",
      "        [0.7960, 0.2040],\n",
      "        [0.9280, 0.0720],\n",
      "        [0.8730, 0.1270],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.5410, 0.4590],\n",
      "        [0.2700, 0.7300],\n",
      "        [0.0500, 0.9500],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.2520, 0.7480],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.2960, 0.7040],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.2440, 0.7560],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.0970, 0.9030],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.5220, 0.4780],\n",
      "        [0.2380, 0.7620],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.7980, 0.2020],\n",
      "        [0.0620, 0.9380]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.5860\n",
      "tensor([[0.5600, 0.4400],\n",
      "        [0.2930, 0.7070],\n",
      "        [0.9250, 0.0750],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.7430, 0.2570],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.4780, 0.5220],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.9630, 0.0370],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.5160, 0.4840],\n",
      "        [0.1780, 0.8220],\n",
      "        [0.2400, 0.7600],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.6270, 0.3730],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.6280, 0.3720],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.3490, 0.6510],\n",
      "        [0.1270, 0.8730],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.7870, 0.2130],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.4010, 0.5990],\n",
      "        [0.9310, 0.0690],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.2480, 0.7520]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.4162\n",
      "tensor([[0.0220, 0.9780],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.5210, 0.4790],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.1210, 0.8790],\n",
      "        [0.8420, 0.1580],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.6600, 0.3400],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.0890, 0.9110],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.1860, 0.8140],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.5900, 0.4100],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.9800, 0.0200],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9310, 0.0690],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.1300, 0.8700],\n",
      "        [0.9560, 0.0440],\n",
      "        [0.1690, 0.8310],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.4640, 0.5360],\n",
      "        [0.7130, 0.2870],\n",
      "        [0.3950, 0.6050]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.5872\n",
      "tensor([[0.6750, 0.3250],\n",
      "        [0.4470, 0.5530],\n",
      "        [0.2010, 0.7990],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.2660, 0.7340],\n",
      "        [0.6160, 0.3840],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.6770, 0.3230],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.6100, 0.3900],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.1590, 0.8410],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.3850, 0.6150],\n",
      "        [0.6640, 0.3360],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.2560, 0.7440],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.2970, 0.7030],\n",
      "        [0.6460, 0.3540],\n",
      "        [0.4230, 0.5770],\n",
      "        [0.8540, 0.1460],\n",
      "        [0.8510, 0.1490],\n",
      "        [0.3600, 0.6400],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.1610, 0.8390],\n",
      "        [0.3970, 0.6030],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.3280, 0.6720]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.3837\n",
      "tensor([[0.8860, 0.1140],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.2780, 0.7220],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.7740, 0.2260],\n",
      "        [0.1790, 0.8210],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.6730, 0.3270]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.4681\n",
      "Epoch 5/10, Loss: -0.49704545454545457\n",
      "tensor([[0.0090, 0.9910],\n",
      "        [0.4440, 0.5560],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.7050, 0.2950],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.2030, 0.7970],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.8620, 0.1380],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.1710, 0.8290],\n",
      "        [0.0570, 0.9430],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.8190, 0.1810],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.1650, 0.8350],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.4450, 0.5550],\n",
      "        [0.5680, 0.4320],\n",
      "        [0.0390, 0.9610],\n",
      "        [0.4920, 0.5080],\n",
      "        [0.2620, 0.7380],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.1190, 0.8810]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.3622\n",
      "tensor([[0.5050, 0.4950],\n",
      "        [0.3530, 0.6470],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.7630, 0.2370],\n",
      "        [0.3820, 0.6180],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.8180, 0.1820],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.7730, 0.2270],\n",
      "        [0.6590, 0.3410],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.4110, 0.5890],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.9360, 0.0640],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.6200, 0.3800],\n",
      "        [0.1260, 0.8740],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.5390, 0.4610],\n",
      "        [0.8990, 0.1010],\n",
      "        [0.3330, 0.6670],\n",
      "        [0.2500, 0.7500]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.6220\n",
      "tensor([[0.5040, 0.4960],\n",
      "        [0.9130, 0.0870],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.5230, 0.4770],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.8520, 0.1480],\n",
      "        [0.6380, 0.3620],\n",
      "        [0.2150, 0.7850],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.0440, 0.9560],\n",
      "        [0.0900, 0.9100],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.6320, 0.3680],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.3290, 0.6710],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.8160, 0.1840],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9120, 0.0880],\n",
      "        [0.7970, 0.2030],\n",
      "        [0.5720, 0.4280],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0390, 0.9610],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.5840, 0.4160],\n",
      "        [0.6580, 0.3420]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5812\n",
      "tensor([[0.2940, 0.7060],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.8810, 0.1190],\n",
      "        [0.8830, 0.1170],\n",
      "        [0.3550, 0.6450],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.9030, 0.0970],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.2320, 0.7680],\n",
      "        [0.3600, 0.6400],\n",
      "        [0.2670, 0.7330],\n",
      "        [0.8600, 0.1400],\n",
      "        [0.9110, 0.0890],\n",
      "        [0.6350, 0.3650],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.3980, 0.6020],\n",
      "        [0.1000, 0.9000],\n",
      "        [0.7170, 0.2830],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.6640, 0.3360],\n",
      "        [0.7310, 0.2690],\n",
      "        [0.6940, 0.3060],\n",
      "        [0.9460, 0.0540],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.0000, 1.0000]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.5644\n",
      "tensor([[0.0640, 0.9360],\n",
      "        [0.2460, 0.7540],\n",
      "        [0.0910, 0.9090],\n",
      "        [0.1210, 0.8790],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.4720, 0.5280],\n",
      "        [0.4370, 0.5630],\n",
      "        [0.0790, 0.9210],\n",
      "        [0.0770, 0.9230],\n",
      "        [0.8060, 0.1940],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.1770, 0.8230],\n",
      "        [0.2340, 0.7660],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.4530, 0.5470],\n",
      "        [0.3030, 0.6970],\n",
      "        [0.1110, 0.8890],\n",
      "        [0.8620, 0.1380],\n",
      "        [0.7100, 0.2900],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.2320, 0.7680],\n",
      "        [0.4740, 0.5260],\n",
      "        [0.9420, 0.0580],\n",
      "        [0.8170, 0.1830],\n",
      "        [0.8380, 0.1620]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.4448\n",
      "tensor([[0.3150, 0.6850],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.4480, 0.5520],\n",
      "        [0.4020, 0.5980],\n",
      "        [0.2460, 0.7540],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.9170, 0.0830],\n",
      "        [0.6850, 0.3150],\n",
      "        [0.9510, 0.0490],\n",
      "        [0.3610, 0.6390],\n",
      "        [0.8640, 0.1360],\n",
      "        [0.4500, 0.5500],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.4200, 0.5800],\n",
      "        [0.9510, 0.0490],\n",
      "        [0.8540, 0.1460],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.9780, 0.0220],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.4010, 0.5990],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.0790, 0.9210],\n",
      "        [0.1670, 0.8330],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.6750, 0.3250],\n",
      "        [0.7690, 0.2310],\n",
      "        [0.7990, 0.2010],\n",
      "        [0.7070, 0.2930]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.5740\n",
      "tensor([[0.8810, 0.1190],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.1730, 0.8270],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.6100, 0.3900],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.7550, 0.2450],\n",
      "        [0.8390, 0.1610],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.5810, 0.4190],\n",
      "        [0.6540, 0.3460],\n",
      "        [0.6740, 0.3260],\n",
      "        [0.5800, 0.4200],\n",
      "        [0.1220, 0.8780],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.6080, 0.3920],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.6020, 0.3980],\n",
      "        [0.8410, 0.1590],\n",
      "        [0.1220, 0.8780],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.8430, 0.1570],\n",
      "        [0.3940, 0.6060],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.8180, 0.1820],\n",
      "        [0.1490, 0.8510]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.5333\n",
      "tensor([[0.9480, 0.0520],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.1380, 0.8620],\n",
      "        [0.5670, 0.4330],\n",
      "        [0.6950, 0.3050],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.4610, 0.5390],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.6530, 0.3470],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.2150, 0.7850],\n",
      "        [0.7040, 0.2960],\n",
      "        [0.2550, 0.7450],\n",
      "        [0.6760, 0.3240],\n",
      "        [0.3150, 0.6850],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.8370, 0.1630],\n",
      "        [0.6410, 0.3590],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.5940, 0.4060],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.0340, 0.9660],\n",
      "        [0.9360, 0.0640],\n",
      "        [0.8980, 0.1020],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.7270, 0.2730],\n",
      "        [0.0230, 0.9770]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.5211\n",
      "tensor([[0.8900, 0.1100],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.6100, 0.3900],\n",
      "        [0.1330, 0.8670],\n",
      "        [0.0990, 0.9010],\n",
      "        [0.2590, 0.7410],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.6130, 0.3870],\n",
      "        [0.8370, 0.1630],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.1580, 0.8420],\n",
      "        [0.3680, 0.6320],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.0390, 0.9610],\n",
      "        [0.6320, 0.3680],\n",
      "        [0.8690, 0.1310],\n",
      "        [0.2990, 0.7010],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1260, 0.8740],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.2600, 0.7400],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.2290, 0.7710],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.2390, 0.7610],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.1300, 0.8700],\n",
      "        [0.8330, 0.1670],\n",
      "        [0.0140, 0.9860]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.4251\n",
      "tensor([[0.1960, 0.8040],\n",
      "        [0.0800, 0.9200],\n",
      "        [0.9120, 0.0880],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.3590, 0.6410],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.8170, 0.1830],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.5950, 0.4050],\n",
      "        [0.0440, 0.9560],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.4270, 0.5730],\n",
      "        [0.9570, 0.0430],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9510, 0.0490],\n",
      "        [0.1330, 0.8670],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.5170, 0.4830],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.6250, 0.3750],\n",
      "        [0.6580, 0.3420]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.5123\n",
      "tensor([[0.4440, 0.5560],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1110, 0.8890],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.5390, 0.4610],\n",
      "        [0.8330, 0.1670]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.3942\n",
      "Epoch 6/10, Loss: -0.50315625\n",
      "tensor([[0.8390, 0.1610],\n",
      "        [0.6120, 0.3880],\n",
      "        [0.7460, 0.2540],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.1420, 0.8580],\n",
      "        [0.2040, 0.7960],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.6810, 0.3190],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.4270, 0.5730],\n",
      "        [0.4460, 0.5540],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.6410, 0.3590],\n",
      "        [0.1290, 0.8710],\n",
      "        [0.7910, 0.2090],\n",
      "        [0.9690, 0.0310],\n",
      "        [0.9350, 0.0650],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.0610, 0.9390],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.5800, 0.4200],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.8570, 0.1430],\n",
      "        [0.9100, 0.0900]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4937\n",
      "tensor([[0.9800, 0.0200],\n",
      "        [0.5910, 0.4090],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.1410, 0.8590],\n",
      "        [0.8370, 0.1630],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.3980, 0.6020],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.5650, 0.4350],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.7950, 0.2050],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.3740, 0.6260],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.0800, 0.9200],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.7880, 0.2120],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.9340, 0.0660],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.6800, 0.3200],\n",
      "        [0.6200, 0.3800],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.0640, 0.9360],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.1880, 0.8120],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.2020, 0.7980]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.4728\n",
      "tensor([[0.8040, 0.1960],\n",
      "        [0.7480, 0.2520],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.4480, 0.5520],\n",
      "        [0.4300, 0.5700],\n",
      "        [0.3930, 0.6070],\n",
      "        [0.0720, 0.9280],\n",
      "        [0.2730, 0.7270],\n",
      "        [0.8130, 0.1870],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.8460, 0.1540],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.1260, 0.8740],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.4070, 0.5930],\n",
      "        [0.5210, 0.4790],\n",
      "        [0.4040, 0.5960],\n",
      "        [0.2770, 0.7230],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.8970, 0.1030],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.7970, 0.2030],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.8500, 0.1500]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.4682\n",
      "tensor([[0.8770, 0.1230],\n",
      "        [0.9350, 0.0650],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.9060, 0.0940],\n",
      "        [0.3240, 0.6760],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.6810, 0.3190],\n",
      "        [0.9460, 0.0540],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.7060, 0.2940],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.3520, 0.6480],\n",
      "        [0.8350, 0.1650],\n",
      "        [0.2710, 0.7290],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.4090, 0.5910],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.8320, 0.1680],\n",
      "        [0.2370, 0.7630],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.5040, 0.4960],\n",
      "        [0.3750, 0.6250],\n",
      "        [0.6130, 0.3870],\n",
      "        [0.3160, 0.6840],\n",
      "        [0.7290, 0.2710],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.0500, 0.9500]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.5891\n",
      "tensor([[0.3310, 0.6690],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.2910, 0.7090],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.2570, 0.7430],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8540, 0.1460],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.3840, 0.6160],\n",
      "        [0.5320, 0.4680],\n",
      "        [0.2750, 0.7250],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.1230, 0.8770],\n",
      "        [0.4800, 0.5200],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.7090, 0.2910],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.3130, 0.6870],\n",
      "        [0.4020, 0.5980],\n",
      "        [0.2670, 0.7330],\n",
      "        [0.3490, 0.6510],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.6620, 0.3380],\n",
      "        [0.2520, 0.7480],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.2110, 0.7890]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.3138\n",
      "tensor([[0.7640, 0.2360],\n",
      "        [0.3920, 0.6080],\n",
      "        [0.9220, 0.0780],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.7610, 0.2390],\n",
      "        [0.2290, 0.7710],\n",
      "        [0.6580, 0.3420],\n",
      "        [0.7020, 0.2980],\n",
      "        [0.4590, 0.5410],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.7830, 0.2170],\n",
      "        [0.6290, 0.3710],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.7310, 0.2690],\n",
      "        [0.4340, 0.5660],\n",
      "        [0.8440, 0.1560],\n",
      "        [0.7000, 0.3000],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.8280, 0.1720],\n",
      "        [0.8060, 0.1940],\n",
      "        [0.3400, 0.6600],\n",
      "        [0.7940, 0.2060],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.9130, 0.0870],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.5380, 0.4620],\n",
      "        [0.8910, 0.1090],\n",
      "        [0.7390, 0.2610],\n",
      "        [0.4230, 0.5770],\n",
      "        [0.5690, 0.4310]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.5518\n",
      "tensor([[0.5050, 0.4950],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.3480, 0.6520],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.4070, 0.5930],\n",
      "        [0.3670, 0.6330],\n",
      "        [0.3320, 0.6680],\n",
      "        [0.7060, 0.2940],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.9220, 0.0780],\n",
      "        [0.7970, 0.2030],\n",
      "        [0.5930, 0.4070],\n",
      "        [0.2810, 0.7190],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.1980, 0.8020],\n",
      "        [0.1980, 0.8020],\n",
      "        [0.0390, 0.9610],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.5190, 0.4810],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.6060, 0.3940],\n",
      "        [0.4910, 0.5090],\n",
      "        [0.2800, 0.7200],\n",
      "        [0.1650, 0.8350]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.5011\n",
      "tensor([[0.0090, 0.9910],\n",
      "        [0.1030, 0.8970],\n",
      "        [0.5510, 0.4490],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9300, 0.0700],\n",
      "        [0.7460, 0.2540],\n",
      "        [0.2420, 0.7580],\n",
      "        [0.4930, 0.5070],\n",
      "        [0.5750, 0.4250],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.4380, 0.5620],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.8720, 0.1280],\n",
      "        [0.1780, 0.8220],\n",
      "        [0.6490, 0.3510],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.5450, 0.4550],\n",
      "        [0.7500, 0.2500],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.1680, 0.8320],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.2350, 0.7650],\n",
      "        [0.3300, 0.6700],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.8230, 0.1770],\n",
      "        [0.6540, 0.3460],\n",
      "        [0.7560, 0.2440],\n",
      "        [0.7390, 0.2610],\n",
      "        [0.3550, 0.6450]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.5131\n",
      "tensor([[0.1860, 0.8140],\n",
      "        [0.7200, 0.2800],\n",
      "        [0.3580, 0.6420],\n",
      "        [0.9350, 0.0650],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.8630, 0.1370],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.4330, 0.5670],\n",
      "        [0.6030, 0.3970],\n",
      "        [0.1420, 0.8580],\n",
      "        [0.1440, 0.8560],\n",
      "        [0.4720, 0.5280],\n",
      "        [0.5480, 0.4520],\n",
      "        [0.9460, 0.0540],\n",
      "        [0.4190, 0.5810],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0890, 0.9110],\n",
      "        [0.2190, 0.7810],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.2410, 0.7590],\n",
      "        [0.8970, 0.1030],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.5030, 0.4970],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.2850, 0.7150],\n",
      "        [0.0900, 0.9100],\n",
      "        [0.9080, 0.0920],\n",
      "        [0.9440, 0.0560]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.5592\n",
      "tensor([[0.0520, 0.9480],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.6160, 0.3840],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.3340, 0.6660],\n",
      "        [0.6300, 0.3700],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.4640, 0.5360],\n",
      "        [0.3300, 0.6700],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.4950, 0.5050],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.1400, 0.8600],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4350, 0.5650],\n",
      "        [0.7110, 0.2890],\n",
      "        [0.3390, 0.6610],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.1230, 0.8770],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.8960, 0.1040],\n",
      "        [0.9360, 0.0640],\n",
      "        [0.0970, 0.9030],\n",
      "        [0.7640, 0.2360],\n",
      "        [0.4160, 0.5840],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.6560, 0.3440]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.6682\n",
      "tensor([[0.9300, 0.0700],\n",
      "        [0.2800, 0.7200],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.8670, 0.1330],\n",
      "        [0.6700, 0.3300],\n",
      "        [0.4850, 0.5150],\n",
      "        [0.3020, 0.6980]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.3201\n",
      "Epoch 7/10, Loss: -0.49555397727272726\n",
      "tensor([[0.6140, 0.3860],\n",
      "        [0.8050, 0.1950],\n",
      "        [0.7690, 0.2310],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.6090, 0.3910],\n",
      "        [0.5880, 0.4120],\n",
      "        [0.5380, 0.4620],\n",
      "        [0.2440, 0.7560],\n",
      "        [0.6740, 0.3260],\n",
      "        [0.3440, 0.6560],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.4590, 0.5410],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.2110, 0.7890],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.9900, 0.0100],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0930, 0.9070],\n",
      "        [0.9280, 0.0720],\n",
      "        [0.6370, 0.3630],\n",
      "        [0.6020, 0.3980],\n",
      "        [0.6970, 0.3030],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.4770, 0.5230],\n",
      "        [0.3330, 0.6670],\n",
      "        [0.3620, 0.6380],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.7860, 0.2140],\n",
      "        [0.4280, 0.5720]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.5560\n",
      "tensor([[0.0720, 0.9280],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.2370, 0.7630],\n",
      "        [0.8860, 0.1140],\n",
      "        [0.9090, 0.0910],\n",
      "        [0.8910, 0.1090],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.7010, 0.2990],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.7830, 0.2170],\n",
      "        [0.1440, 0.8560],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.4390, 0.5610],\n",
      "        [0.5570, 0.4430],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.3680, 0.6320],\n",
      "        [0.8290, 0.1710],\n",
      "        [0.8030, 0.1970],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.6510, 0.3490],\n",
      "        [0.6830, 0.3170],\n",
      "        [0.5630, 0.4370],\n",
      "        [0.0730, 0.9270]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5470\n",
      "tensor([[0.5750, 0.4250],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.5210, 0.4790],\n",
      "        [0.4710, 0.5290],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.8620, 0.1380],\n",
      "        [0.5030, 0.4970],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.3210, 0.6790],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.7540, 0.2460],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.5140, 0.4860],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.3020, 0.6980],\n",
      "        [0.8440, 0.1560],\n",
      "        [0.8950, 0.1050],\n",
      "        [0.3880, 0.6120],\n",
      "        [0.2360, 0.7640],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.7870, 0.2130],\n",
      "        [0.2030, 0.7970],\n",
      "        [0.9680, 0.0320],\n",
      "        [0.7520, 0.2480],\n",
      "        [0.2340, 0.7660]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5614\n",
      "tensor([[0.7450, 0.2550],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.7000, 0.3000],\n",
      "        [0.1000, 0.9000],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.4730, 0.5270],\n",
      "        [0.6220, 0.3780],\n",
      "        [0.5460, 0.4540],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.2520, 0.7480],\n",
      "        [0.7400, 0.2600],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.5400, 0.4600],\n",
      "        [0.2040, 0.7960],\n",
      "        [0.1350, 0.8650],\n",
      "        [0.5350, 0.4650],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.8340, 0.1660],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1980, 0.8020],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.9280, 0.0720],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.8270, 0.1730],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.6950, 0.3050],\n",
      "        [0.3270, 0.6730],\n",
      "        [0.0030, 0.9970]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.4317\n",
      "tensor([[0.1670, 0.8330],\n",
      "        [0.3050, 0.6950],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.3450, 0.6550],\n",
      "        [0.8310, 0.1690],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.6200, 0.3800],\n",
      "        [0.3890, 0.6110],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.4780, 0.5220],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.4810, 0.5190],\n",
      "        [0.3330, 0.6670],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.6630, 0.3370],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.8580, 0.1420],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.7750, 0.2250],\n",
      "        [0.8270, 0.1730],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.9090, 0.0910],\n",
      "        [0.0010, 0.9990]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.4528\n",
      "tensor([[0.0330, 0.9670],\n",
      "        [0.5070, 0.4930],\n",
      "        [0.5930, 0.4070],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.4230, 0.5770],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.9370, 0.0630],\n",
      "        [0.3560, 0.6440],\n",
      "        [0.1050, 0.8950],\n",
      "        [0.3220, 0.6780],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.0800, 0.9200],\n",
      "        [0.7210, 0.2790],\n",
      "        [0.9320, 0.0680],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.6830, 0.3170],\n",
      "        [0.3730, 0.6270],\n",
      "        [0.3360, 0.6640],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.8090, 0.1910],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.7800, 0.2200],\n",
      "        [0.2320, 0.7680],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.7490, 0.2510],\n",
      "        [0.0690, 0.9310],\n",
      "        [0.3620, 0.6380],\n",
      "        [0.2630, 0.7370],\n",
      "        [0.3840, 0.6160]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.4437\n",
      "tensor([[0.7500, 0.2500],\n",
      "        [0.9030, 0.0970],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.7470, 0.2530],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.1670, 0.8330],\n",
      "        [0.8750, 0.1250],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.3840, 0.6160],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.6010, 0.3990],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.6140, 0.3860],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.1660, 0.8340],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.8980, 0.1020],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.7380, 0.2620],\n",
      "        [0.7080, 0.2920],\n",
      "        [0.8630, 0.1370],\n",
      "        [0.7640, 0.2360],\n",
      "        [0.0570, 0.9430]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.5612\n",
      "tensor([[0.0690, 0.9310],\n",
      "        [0.2750, 0.7250],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.0720, 0.9280],\n",
      "        [0.8590, 0.1410],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.3310, 0.6690],\n",
      "        [0.2900, 0.7100],\n",
      "        [0.5940, 0.4060],\n",
      "        [0.7170, 0.2830],\n",
      "        [0.8160, 0.1840],\n",
      "        [0.6630, 0.3370],\n",
      "        [0.5770, 0.4230],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.7040, 0.2960],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.3450, 0.6550],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.5790, 0.4210],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.1080, 0.8920],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.1460, 0.8540]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.3905\n",
      "tensor([[0.9140, 0.0860],\n",
      "        [0.8330, 0.1670],\n",
      "        [0.5960, 0.4040],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.5450, 0.4550],\n",
      "        [0.8480, 0.1520],\n",
      "        [0.1580, 0.8420],\n",
      "        [0.9220, 0.0780],\n",
      "        [0.2220, 0.7780],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.2260, 0.7740],\n",
      "        [0.4670, 0.5330],\n",
      "        [0.1000, 0.9000],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.8680, 0.1320],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.5810, 0.4190],\n",
      "        [0.5410, 0.4590],\n",
      "        [0.6210, 0.3790],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1830, 0.8170],\n",
      "        [0.5480, 0.4520],\n",
      "        [0.6580, 0.3420],\n",
      "        [0.3470, 0.6530],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.9060, 0.0940],\n",
      "        [0.3190, 0.6810],\n",
      "        [0.6120, 0.3880],\n",
      "        [0.1590, 0.8410]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.4086\n",
      "tensor([[1.0000, 0.0000],\n",
      "        [0.6740, 0.3260],\n",
      "        [0.6300, 0.3700],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.3700, 0.6300],\n",
      "        [0.1400, 0.8600],\n",
      "        [0.9370, 0.0630],\n",
      "        [0.6320, 0.3680],\n",
      "        [0.5380, 0.4620],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.3380, 0.6620],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.0580, 0.9420],\n",
      "        [0.1450, 0.8550],\n",
      "        [0.9110, 0.0890],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.8490, 0.1510],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.4890, 0.5110],\n",
      "        [0.4940, 0.5060],\n",
      "        [0.1170, 0.8830],\n",
      "        [0.2200, 0.7800],\n",
      "        [0.9310, 0.0690],\n",
      "        [0.2130, 0.7870],\n",
      "        [0.1220, 0.8780]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.3629\n",
      "tensor([[0.7570, 0.2430],\n",
      "        [0.2780, 0.7220],\n",
      "        [0.7490, 0.2510],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.2770, 0.7230],\n",
      "        [0.6340, 0.3660],\n",
      "        [0.8020, 0.1980],\n",
      "        [0.5700, 0.4300]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.3686\n",
      "Epoch 8/10, Loss: -0.46222443181818174\n",
      "tensor([[0.2990, 0.7010],\n",
      "        [0.0570, 0.9430],\n",
      "        [0.7150, 0.2850],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.3400, 0.6600],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.9200, 0.0800],\n",
      "        [0.9330, 0.0670],\n",
      "        [0.2560, 0.7440],\n",
      "        [0.5820, 0.4180],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.4320, 0.5680],\n",
      "        [0.2110, 0.7890],\n",
      "        [0.3730, 0.6270],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.2230, 0.7770],\n",
      "        [0.5860, 0.4140],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.3940, 0.6060],\n",
      "        [0.7720, 0.2280],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.3890, 0.6110],\n",
      "        [0.7160, 0.2840],\n",
      "        [0.1920, 0.8080],\n",
      "        [0.2110, 0.7890],\n",
      "        [0.7680, 0.2320],\n",
      "        [0.3270, 0.6730],\n",
      "        [0.3540, 0.6460],\n",
      "        [0.0410, 0.9590]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4371\n",
      "tensor([[0.6340, 0.3660],\n",
      "        [0.7460, 0.2540],\n",
      "        [0.2160, 0.7840],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.9460, 0.0540],\n",
      "        [0.1420, 0.8580],\n",
      "        [0.7400, 0.2600],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.2410, 0.7590],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.7960, 0.2040],\n",
      "        [0.5720, 0.4280],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.5870, 0.4130],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.4840, 0.5160],\n",
      "        [0.4840, 0.5160],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.5980, 0.4020],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.4270, 0.5730],\n",
      "        [0.1310, 0.8690],\n",
      "        [0.6940, 0.3060],\n",
      "        [0.5010, 0.4990],\n",
      "        [0.8660, 0.1340],\n",
      "        [0.5130, 0.4870]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5553\n",
      "tensor([[0.0080, 0.9920],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.7340, 0.2660],\n",
      "        [0.7860, 0.2140],\n",
      "        [0.2710, 0.7290],\n",
      "        [0.5030, 0.4970],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.7310, 0.2690],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.1070, 0.8930],\n",
      "        [0.2970, 0.7030],\n",
      "        [0.2150, 0.7850],\n",
      "        [0.1810, 0.8190],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.5240, 0.4760],\n",
      "        [0.2230, 0.7770],\n",
      "        [0.5930, 0.4070],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.1750, 0.8250],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.6080, 0.3920],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.5990, 0.4010]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5680\n",
      "tensor([[0.9610, 0.0390],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.7460, 0.2540],\n",
      "        [0.4910, 0.5090],\n",
      "        [0.3870, 0.6130],\n",
      "        [0.3860, 0.6140],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.4220, 0.5780],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.3900, 0.6100],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.2500, 0.7500],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.9090, 0.0910],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.8130, 0.1870],\n",
      "        [0.2490, 0.7510],\n",
      "        [0.3930, 0.6070],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.3950, 0.6050],\n",
      "        [0.4510, 0.5490],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.1010, 0.8990],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.4940, 0.5060],\n",
      "        [0.4410, 0.5590],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.6130, 0.3870],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.2700, 0.7300]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.6060\n",
      "tensor([[0.9460, 0.0540],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.6710, 0.3290],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.3830, 0.6170],\n",
      "        [0.3370, 0.6630],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.2770, 0.7230],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.6160, 0.3840],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.0920, 0.9080],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0870, 0.9130],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.1410, 0.8590],\n",
      "        [0.3780, 0.6220],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.4240, 0.5760],\n",
      "        [0.9010, 0.0990],\n",
      "        [0.9420, 0.0580],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.2630, 0.7370],\n",
      "        [0.1710, 0.8290],\n",
      "        [0.8130, 0.1870],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.7870, 0.2130],\n",
      "        [0.4420, 0.5580]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.4654\n",
      "tensor([[0.1500, 0.8500],\n",
      "        [0.1990, 0.8010],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.3240, 0.6760],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.6730, 0.3270],\n",
      "        [0.9080, 0.0920],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.1680, 0.8320],\n",
      "        [0.6840, 0.3160],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.6880, 0.3120],\n",
      "        [0.1680, 0.8320],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.3260, 0.6740],\n",
      "        [0.6410, 0.3590],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.7320, 0.2680],\n",
      "        [0.1410, 0.8590],\n",
      "        [0.6740, 0.3260],\n",
      "        [0.8540, 0.1460],\n",
      "        [0.4600, 0.5400],\n",
      "        [0.6050, 0.3950],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.1050, 0.8950],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.2130, 0.7870],\n",
      "        [0.1720, 0.8280],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0940, 0.9060],\n",
      "        [0.6850, 0.3150]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.4645\n",
      "tensor([[0.9920, 0.0080],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.1030, 0.8970],\n",
      "        [0.6940, 0.3060],\n",
      "        [0.5330, 0.4670],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.0990, 0.9010],\n",
      "        [0.5690, 0.4310],\n",
      "        [0.6100, 0.3900],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.9340, 0.0660],\n",
      "        [0.6050, 0.3950],\n",
      "        [0.1460, 0.8540],\n",
      "        [0.4300, 0.5700],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.6130, 0.3870],\n",
      "        [0.5320, 0.4680],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.1330, 0.8670],\n",
      "        [0.6620, 0.3380],\n",
      "        [0.5370, 0.4630],\n",
      "        [0.8190, 0.1810],\n",
      "        [0.1760, 0.8240],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.7850, 0.2150]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.5160\n",
      "tensor([[0.7330, 0.2670],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.1570, 0.8430],\n",
      "        [0.0730, 0.9270],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.2660, 0.7340],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.4390, 0.5610],\n",
      "        [0.6290, 0.3710],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.6240, 0.3760],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2250, 0.7750],\n",
      "        [0.1870, 0.8130],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.8850, 0.1150],\n",
      "        [0.0140, 0.9860],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.1880, 0.8120],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.5860, 0.4140],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.9280, 0.0720]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.4791\n",
      "tensor([[0.0850, 0.9150],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.9060, 0.0940],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.5270, 0.4730],\n",
      "        [0.7420, 0.2580],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.3610, 0.6390],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.1330, 0.8670],\n",
      "        [0.0950, 0.9050],\n",
      "        [0.0770, 0.9230],\n",
      "        [0.4170, 0.5830],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8280, 0.1720],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.1010, 0.8990],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.3850, 0.6150],\n",
      "        [0.1890, 0.8110],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.4090, 0.5910],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.8110, 0.1890],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.9850, 0.0150]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.4031\n",
      "tensor([[0.9470, 0.0530],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.0890, 0.9110],\n",
      "        [0.6040, 0.3960],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.2100, 0.7900],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.2900, 0.7100],\n",
      "        [0.1220, 0.8780],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.1330, 0.8670],\n",
      "        [0.3890, 0.6110],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.7240, 0.2760],\n",
      "        [0.2760, 0.7240],\n",
      "        [0.6920, 0.3080],\n",
      "        [0.2800, 0.7200],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.0690, 0.9310],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.7900, 0.2100],\n",
      "        [1.0000, 0.0000]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.4845\n",
      "tensor([[0.4350, 0.5650],\n",
      "        [0.8110, 0.1890],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.1630, 0.8370],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8780, 0.1220]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.3291\n",
      "Epoch 9/10, Loss: -0.4825539772727273\n",
      "tensor([[0.9610, 0.0390],\n",
      "        [0.8280, 0.1720],\n",
      "        [0.7840, 0.2160],\n",
      "        [0.7180, 0.2820],\n",
      "        [0.1790, 0.8210],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.6080, 0.3920],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.3390, 0.6610],\n",
      "        [0.4730, 0.5270],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.8590, 0.1410],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2410, 0.7590],\n",
      "        [0.8340, 0.1660],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.0020, 0.9980],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4930, 0.5070],\n",
      "        [0.1000, 0.9000],\n",
      "        [0.6160, 0.3840],\n",
      "        [0.0790, 0.9210],\n",
      "        [0.3440, 0.6560],\n",
      "        [0.2240, 0.7760],\n",
      "        [0.8990, 0.1010],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.3020, 0.6980]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.6284\n",
      "tensor([[0.5490, 0.4510],\n",
      "        [0.0390, 0.9610],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.4400, 0.5600],\n",
      "        [0.6770, 0.3230],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.6530, 0.3470],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.7780, 0.2220],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.2260, 0.7740],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.3550, 0.6450],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.8870, 0.1130],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.5370, 0.4630],\n",
      "        [0.4160, 0.5840],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.0980, 0.9020],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.4600, 0.5400],\n",
      "        [0.0980, 0.9020],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.0830, 0.9170],\n",
      "        [0.9500, 0.0500]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.4259\n",
      "tensor([[0.5350, 0.4650],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.6480, 0.3520],\n",
      "        [0.7630, 0.2370],\n",
      "        [0.3270, 0.6730],\n",
      "        [0.6380, 0.3620],\n",
      "        [0.8080, 0.1920],\n",
      "        [0.1750, 0.8250],\n",
      "        [0.5410, 0.4590],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.6420, 0.3580],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.9300, 0.0700],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.2180, 0.7820],\n",
      "        [0.5590, 0.4410],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.0730, 0.9270],\n",
      "        [0.1030, 0.8970],\n",
      "        [0.6470, 0.3530],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.2420, 0.7580],\n",
      "        [0.7190, 0.2810],\n",
      "        [0.2600, 0.7400],\n",
      "        [0.1350, 0.8650],\n",
      "        [0.4880, 0.5120],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0290, 0.9710]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.4194\n",
      "tensor([[0.6380, 0.3620],\n",
      "        [0.3520, 0.6480],\n",
      "        [0.4130, 0.5870],\n",
      "        [0.6500, 0.3500],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.4600, 0.5400],\n",
      "        [0.0650, 0.9350],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.4300, 0.5700],\n",
      "        [0.6430, 0.3570],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.3700, 0.6300],\n",
      "        [0.2730, 0.7270],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.9200, 0.0800],\n",
      "        [0.2700, 0.7300],\n",
      "        [0.5290, 0.4710],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.4570, 0.5430],\n",
      "        [0.4410, 0.5590],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.4240, 0.5760],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.7290, 0.2710],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.9570, 0.0430],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.0440, 0.9560],\n",
      "        [0.0660, 0.9340]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 4 concluído com loss: -0.5775\n",
      "tensor([[0.5360, 0.4640],\n",
      "        [0.4600, 0.5400],\n",
      "        [0.4110, 0.5890],\n",
      "        [0.5450, 0.4550],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.0000, 1.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0660, 0.9340],\n",
      "        [0.2880, 0.7120],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.3040, 0.6960],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.8100, 0.1900],\n",
      "        [0.7880, 0.2120],\n",
      "        [0.0910, 0.9090],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.8930, 0.1070],\n",
      "        [0.3330, 0.6670],\n",
      "        [0.5290, 0.4710],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.6380, 0.3620],\n",
      "        [0.1990, 0.8010],\n",
      "        [0.5170, 0.4830],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.3200, 0.6800],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.4800, 0.5200],\n",
      "        [0.7050, 0.2950],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.5890, 0.4110]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 5 concluído com loss: -0.5627\n",
      "tensor([[0.6110, 0.3890],\n",
      "        [0.2200, 0.7800],\n",
      "        [0.1450, 0.8550],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.3580, 0.6420],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.6490, 0.3510],\n",
      "        [0.8660, 0.1340],\n",
      "        [0.7030, 0.2970],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.2840, 0.7160],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.4740, 0.5260],\n",
      "        [0.6200, 0.3800],\n",
      "        [0.6720, 0.3280],\n",
      "        [0.7870, 0.2130],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.4950, 0.5050],\n",
      "        [0.7440, 0.2560],\n",
      "        [0.4980, 0.5020],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.8640, 0.1360],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.2640, 0.7360],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.5890, 0.4110],\n",
      "        [0.4490, 0.5510],\n",
      "        [0.9560, 0.0440],\n",
      "        [0.3160, 0.6840]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 6 concluído com loss: -0.5264\n",
      "tensor([[0.3110, 0.6890],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.1770, 0.8230],\n",
      "        [0.8570, 0.1430],\n",
      "        [0.8800, 0.1200],\n",
      "        [0.7350, 0.2650],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.2250, 0.7750],\n",
      "        [0.8070, 0.1930],\n",
      "        [0.1630, 0.8370],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.3310, 0.6690],\n",
      "        [0.5550, 0.4450],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.3100, 0.6900],\n",
      "        [0.6200, 0.3800],\n",
      "        [0.8980, 0.1020],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.7350, 0.2650],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.2070, 0.7930],\n",
      "        [0.1690, 0.8310],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.8360, 0.1640],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.0760, 0.9240],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.2930, 0.7070]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 7 concluído com loss: -0.4372\n",
      "tensor([[0.9590, 0.0410],\n",
      "        [0.3900, 0.6100],\n",
      "        [0.3170, 0.6830],\n",
      "        [0.5450, 0.4550],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.6380, 0.3620],\n",
      "        [0.5400, 0.4600],\n",
      "        [0.1740, 0.8260],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.8100, 0.1900],\n",
      "        [0.2820, 0.7180],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.4240, 0.5760],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0640, 0.9360],\n",
      "        [0.3610, 0.6390],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.8160, 0.1840],\n",
      "        [0.5170, 0.4830],\n",
      "        [0.4080, 0.5920],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.1450, 0.8550],\n",
      "        [0.6680, 0.3320],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.0890, 0.9110],\n",
      "        [0.1790, 0.8210],\n",
      "        [0.5600, 0.4400],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.0000, 1.0000]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 8 concluído com loss: -0.4763\n",
      "tensor([[0.9010, 0.0990],\n",
      "        [0.1400, 0.8600],\n",
      "        [0.9360, 0.0640],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.2360, 0.7640],\n",
      "        [0.1170, 0.8830],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.8440, 0.1560],\n",
      "        [0.6910, 0.3090],\n",
      "        [0.3230, 0.6770],\n",
      "        [0.2590, 0.7410],\n",
      "        [0.2880, 0.7120],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.9340, 0.0660],\n",
      "        [0.4900, 0.5100],\n",
      "        [0.9200, 0.0800],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.8450, 0.1550],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.7530, 0.2470],\n",
      "        [0.1310, 0.8690],\n",
      "        [0.1760, 0.8240],\n",
      "        [0.8580, 0.1420],\n",
      "        [0.7130, 0.2870],\n",
      "        [0.1400, 0.8600],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.8980, 0.1020],\n",
      "        [0.1430, 0.8570]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 9 concluído com loss: -0.4321\n",
      "tensor([[0.9270, 0.0730],\n",
      "        [0.2550, 0.7450],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.4730, 0.5270],\n",
      "        [0.5640, 0.4360],\n",
      "        [0.7970, 0.2030],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.7970, 0.2030],\n",
      "        [0.4730, 0.5270],\n",
      "        [0.1770, 0.8230],\n",
      "        [0.6760, 0.3240],\n",
      "        [0.7610, 0.2390],\n",
      "        [0.0790, 0.9210],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.5110, 0.4890],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.8420, 0.1580],\n",
      "        [0.0700, 0.9300],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.3690, 0.6310],\n",
      "        [0.8670, 0.1330],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.7910, 0.2090],\n",
      "        [0.1140, 0.8860],\n",
      "        [0.9220, 0.0780],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.8530, 0.1470]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 10 concluído com loss: -0.4320\n",
      "tensor([[0.7890, 0.2110],\n",
      "        [0.9510, 0.0490],\n",
      "        [0.8520, 0.1480],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.6960, 0.3040],\n",
      "        [0.2110, 0.7890],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.5470, 0.4530]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "  Batch 11 concluído com loss: -0.4330\n",
      "Epoch 10/10, Loss: -0.48645170454545456\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        label = label.unsqueeze(1)\n",
    "        \n",
    "        # Converta os tensores para o tipo correto\n",
    "        image = image.cpu()\n",
    "        label = label.cpu()\n",
    "\n",
    "        optimizer.zero_grad()  # Zere os gradientes\n",
    "\n",
    "        # Passe as imagens pelo modelo\n",
    "        prediction = model(image)\n",
    "\n",
    "        prediction = prediction.cpu()\n",
    "\n",
    "        #Get prediction label from the index with the maximum score\n",
    "        #prediction_label = torch.argmax(prediction, dim=1)\n",
    "        print(prediction)\n",
    "\n",
    "        #prediction_label = prediction_label.unsqueeze(1)\n",
    "        # Calcule a perda\n",
    "        \n",
    "        loss = loss_func(prediction, label.squeeze().long())\n",
    "\n",
    "        # Propagação para trás e atualização dos pesos\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Armazene as informações\n",
    "        total_loss.append(loss.item())\n",
    "        print(f\"  Batch {batch_idx + 1} concluído com loss: {loss.item():.4f}\")\n",
    "        \n",
    "    avg_loss = np.mean(total_loss)\n",
    "    loss_list.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "    model_save_path = f\"model_epoch_{epoch}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Oy111XeE_cm-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3409\n",
      "Recall: 0.6000\n",
      "F1 Score: 0.4348\n",
      "Acurácia: 0.5244\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        label = label.unsqueeze(1)\n",
    "        \n",
    "        # Converta os tensores para o tipo correto\n",
    "        image = image.cpu()\n",
    "        label = label.cpu()\n",
    "        # image, label = image.type(dtype=torch.cuda.FloatTensor), label.type(dtype=torch.cuda.LongTensor)\n",
    "        try:\n",
    "            prediction = model(image)\n",
    "            predicted_class = prediction.argmax(dim=1)\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_predictions.extend(predicted_class.cpu().numpy())\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calcular acurácia\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Acurácia: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gerar matriz de confusão\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Plotar matriz de confusão\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GPU Enabled Condensed Version of  multiqubit and multioutput QML-Hybrid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "quantumResearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1eb8817a50524ce1af23052011be56f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24f07891b0324ca78c4c7f0beee98566": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f56767fae03484688536b828846b56a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "505d1bdc25414cee9dfbc3204dfc0c93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "552e8d190a1d437b920bc7d3f1e1af61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58adc826bab3458ca9cb8e325ce05f2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59f8519d3d2144d683558aca466da131": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f1bb84efe844ee2b4fc27afe2a212c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64575c54d09d455281be57a8a0260346": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6611d138ef6e432f8ce0cf52cb1a07c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e827e8d2e88f4c71ae86f3c8538c84c0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ca965b900b1461eaa28f2a6b5398c73",
      "value": 1
     }
    },
    "69d560892ba440f89b50641014d1fd06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ca965b900b1461eaa28f2a6b5398c73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "90586e7287474ecfae458ff3b0a74efd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae991db157b34830a4824661dc2ea07d",
       "IPY_MODEL_d9afc24be121433da98462d5ca8d8690"
      ],
      "layout": "IPY_MODEL_f2cd8d5132c444f0b25b353bdcd9d7ab"
     }
    },
    "9255a79718b040bbb8ec080d440304c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1eb8817a50524ce1af23052011be56f4",
      "placeholder": "​",
      "style": "IPY_MODEL_24f07891b0324ca78c4c7f0beee98566",
      "value": " 32768/? [00:00&lt;00:00, 369344.38it/s]"
     }
    },
    "9276c41a3c6d41d3b60d31b30be07113": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a29264a8b5e6411eac0d3dae64693251": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe01b032a0c84aa695c9640550aab9fb",
       "IPY_MODEL_9255a79718b040bbb8ec080d440304c5"
      ],
      "layout": "IPY_MODEL_9276c41a3c6d41d3b60d31b30be07113"
     }
    },
    "a530b88ca002433e86872d16c37e551d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505d1bdc25414cee9dfbc3204dfc0c93",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f56767fae03484688536b828846b56a",
      "value": 1
     }
    },
    "ae991db157b34830a4824661dc2ea07d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f1bb84efe844ee2b4fc27afe2a212c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef091b36eb3c48dcb0aaf09eec350971",
      "value": 1
     }
    },
    "af12e2a48e7940d0bff7731249e433f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a530b88ca002433e86872d16c37e551d",
       "IPY_MODEL_c30500854da54f07b2345d5cc55deee3"
      ],
      "layout": "IPY_MODEL_59f8519d3d2144d683558aca466da131"
     }
    },
    "b674dba95756437fb8eb209b726e7dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbfbdbd1d45e4de0b32e19125b29f71d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6611d138ef6e432f8ce0cf52cb1a07c4",
       "IPY_MODEL_ff58db68cca442cea4055e678574b2c2"
      ],
      "layout": "IPY_MODEL_552e8d190a1d437b920bc7d3f1e1af61"
     }
    },
    "c30500854da54f07b2345d5cc55deee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d560892ba440f89b50641014d1fd06",
      "placeholder": "​",
      "style": "IPY_MODEL_b674dba95756437fb8eb209b726e7dd8",
      "value": " 9920512/? [00:20&lt;00:00, 42152945.94it/s]"
     }
    },
    "d9afc24be121433da98462d5ca8d8690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de7bb8d497e14b09b1921f670bb59efb",
      "placeholder": "​",
      "style": "IPY_MODEL_f1a712b491b546029d157a17a0d6337e",
      "value": " 8192/? [00:00&lt;00:00, 18970.79it/s]"
     }
    },
    "de7bb8d497e14b09b1921f670bb59efb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e827e8d2e88f4c71ae86f3c8538c84c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea70115f0ada4a769c55113327333393": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef091b36eb3c48dcb0aaf09eec350971": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1a712b491b546029d157a17a0d6337e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2cd8d5132c444f0b25b353bdcd9d7ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9cd8031e436418595d28cf344fe2e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe01b032a0c84aa695c9640550aab9fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64575c54d09d455281be57a8a0260346",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9cd8031e436418595d28cf344fe2e4f",
      "value": 1
     }
    },
    "ff58db68cca442cea4055e678574b2c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58adc826bab3458ca9cb8e325ce05f2c",
      "placeholder": "​",
      "style": "IPY_MODEL_ea70115f0ada4a769c55113327333393",
      "value": " 1654784/? [00:19&lt;00:00, 138150.43it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
